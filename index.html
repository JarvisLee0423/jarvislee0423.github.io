<!doctype html>
<html>
	<head>
		<title>Jiahao LI (Jarvis Lee)</title>
		<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
		<meta name="keywords" content="Jiahao LI, City University of Hong Kong"> 
		<meta name="description" content="The homepage of Jiahao LI">
		<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
		<script>
			(
				function(i,s,o,g,r,a,m){
					i['GoogleAnalyticsObject']=r;
					i[r]=i[r] || function(){
						(
							i[r].q=i[r].q || []
						).push(arguments)
					}, i[r].l=1*new Date();
					a=s.createElement(o), m=s.getElementsByTagName(o)[0];
					a.async=1;
					a.src=g;
					m.parentNode.insertBefore(a,m)
				}
			)
			(
				window,document,'script','//www.google-analytics.com/analytics.js','ga'
			);
			ga('create', 'UA-137722442-1', 'auto');
			ga('send', 'pageview');
		</script>
	</head>
	<body>
		<div id="layout-content" style="margin-top:25px">
			<img src="./assets/img/my_picture.jpg" style="float:right; margin-top:30px; width: 20%;border-radius: 6px;" />
			<table>
				<tbody>
					<tr>
						<td width="75%">
							<div id="toptitle">
								<h1>Jiahao LI (Jarvis Lee) | 李嘉昊</h1>
							</div>
							<h3>Ph.D. Student</h3>
							<p>
								City University of Hong Kong (CityUHK)</br>
							</p>
							<p>
								<a href="mailto:jiahali2-c@my.city.edu.hk">Email</a> &nbsp;/&nbsp;
								<a href="assets/resume_xgw.pdf">CV</a> &nbsp;/&nbsp;
								<a href="https://scholar.google.com/citations?hl=en&user=yjAHyi0AAAAJ">Scholar</a> &nbsp;/&nbsp;
								<a href="https://github.com/JarvisLee0423">Github</a>
							</p>
						</td>
					</tr>
				</tbody>
			</table>
			
			<h2>About Me</h2>
			<p>
				I am currently a first-year Ph.D. Student at <a href="https://www.cityu.edu.hk/">City University of Hong Kong (CityUHK)</a>, supervised by <a href="https://scholar.google.com/citations?user=bow_liAAAAAJ&hl=en">Prof. Jianping Wang</a>. My current research direction is <strong>Autonomous Driving</strong>, especially <strong>3D Occupancy Prediction</strong>, <strong>3D Scene Reconstruction (Depth Estimation & Stereo Matching)</strong>. </br>
			</p>
			<p>
				Prior to that, I obtained the Master's Degree of Science in Computer Science from <a href="https://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong (CUHK)</a> in 2022, supervised by <a href="https://scholar.google.com/citations?hl=en&user=GJDv8mwAAAAJ&view_op=list_works&sortby=pubdate">Prof. Kin Hong Wong</a> and the Bachelor's Degree of Science (Honours) in Computer Science and Technology (First Class) from <a href="https://www.hkbu.edu.hk/">Hong Kong Baptist University (HKBU)</a> in 2021, supervised by <a href="https://fst.uic.edu.cn/en/faculty/faculty.htm#/goliathli/en">Prof. Zhiyuan LI</a> and <a href="https://fst.uic.edu.cn/en/faculty/faculty.htm#/raymondshtlee/en">Prof. Raymond Lee</a>. After graduating from CUHK, I also spent a wonderful time from 2022 to 2024, working at the <a href="https://www.picoxr.com/cn">PICO MR Team</a> of <a href="https://www.bytedance.com/en/">ByteDance Ltd.</a> as a Computer Vision Algorithm Engineer focused on Depth Estimation and 3D Reconstruction, mentored by <a href="https://www.liuxiao.org/">Xiao Liu</a>.
			</p>
			
			<h2>News</h2>
			<ul>
				<li>[2025/06] &#128640;&#128640;&#128640; One paper is accepted by ICCV 2025! &#128640;&#128640;&#128640;</li>
				<li>[2024/08] &#127881;&#127881;&#127881; I obtained the Ph.D. offer at CityUHK and started my Ph.D. studies! &#127881;&#127881;&#127881;</li>
				<li>[2024/05] &#128293;&#128293;&#128293; Our team (<strong>FSM Speed</strong>) has won the <strong>Championship</strong> at <strong>the 17th F1TENTH Autonomous Grand Prix</strong> during the CPS-IoT Week 2024 in Hong Kong, supervised by <a href="https://scholar.google.com/citations?user=bow_liAAAAAJ&hl=en">Prof. Jianping Wang</a>. The team members include Ph.D. students Jinghuai Deng, Bingyuan Huang, Xiaoyun Dong, Hua Hu, and <strong>Jiahao LI</strong>. &#128293;&#128293;&#128293;</li>
			</ul>
			
			<h2>Publications</h2>
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
				<tbody>
					<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
						<td style="padding:20px;width:20%;vertical-align:middle">
							<div class="one">
								<img src='./assets/img/great_stereo.jpg' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
							</div>
						</td>
						<td style="padding:20px;width:80%;vertical-align:middle">
							<span class="papertitle">Global Regulation and Excitation via Attention Tuning for Stereo Matching</span><br>
							<strong>Jiahao LI</strong>, Xinhong Chen, Zhengmin JIANG, Qian Zhou, Yung-Hui Li, Jianping Wang<br>
							<em>ICCV 2025</em><br>
							<a href="https://github.com/JarvisLee0423/GREAT-Stereo">Paper</a>
							/
							<a href="https://github.com/JarvisLee0423/GREAT-Stereo">Code</a>
							<p></p>
							<p>
								A universal framework (GREAT) that can be integrated into existing iterative stereo-matching methods to improve the performance in ill-posed regions by using three well-designed attention mechanisms (Spatial Attention, Matching Attention, and Volume Attention) to incorporate global geometric information.
							</p>
						</td>
					</tr>
				</tbody>
			</table>
			
			<h2>Previous Publications</h2>
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
				<tbody>
					<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
						<td style="padding:20px;width:20%;vertical-align:middle">
							<div class="one">
								<img src='./assets/img/aeacv_stereo.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
							</div>
						</td>
						<td style="padding:20px;width:80%;vertical-align:middle">
							<span class="papertitle">Adaptive Error Aware Cost Volume for Stereo Matching</span><br>
							<strong>Jiahao LI</strong>, Zhengxin Li, Yiping Bao, Guangyuan Zhou, Qiang Rao, Xiao Liu<br>
							<em>ECCV 2024 Submission ID 4123</em><br>
							<a href="https://github.com/JarvisLee0423/AEACV-Stereo">Code</a>
							<p></p>
							<p>
								We present a dynamic sampling strategy based on an error map, significantly accelerating iterative speed and a cost volume construction method that effectively filters out noise from ill-posed regions, enhancing the accuracy of disparity prediction.
							</p>
							<p>
								<font color="red">Warning: This paper has not been accepted by the main conference of ECCV 2024. Due to company policy, it has not been republished in any other conferences or workshops, nor has it been published on arXiv. If you have any problems, feel free to contact me by email.</font>
							</p>
						</td>
					</tr>

					<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
						<td style="padding:20px;width:20%;vertical-align:middle">
							<div class="one">
								<img src='./assets/img/chaotic_oscillator.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
							</div>
						</td>
						<td style="padding:20px;width:80%;vertical-align:middle">
							<span class="papertitle">Chaotic Bi-LSTM and Attention HLCO Predictor Based Quantum Price Level Fuzzy Logic Trading System</span><br>
							<strong>Jiahao LI</strong>, Zihao Huang, Lirong Lin, Yuchen Guo, Raymond Lee<br>
							<em>Soft Computing 2023</em><br>
							<a href="https://www.researchsquare.com/article/rs-1819548/latest.pdf">Paper</a>
							/
							<a href="https://github.com/JarvisLee0423/Chaotic-Quantum-Finance-Trading-System">Code</a>
							<p></p>
							<p>
								We propose a novel neural network guided price predictor with Attention Mechanism, Bidirectional LSTM, Chaotic Neuro-Oscillator, and Quantum Price Level to predict future High, Low, Close, and Open (HLCO) prices, and a novel fuzzy logic-based trading strategy combined with the above price predictor to remedy fixed order-triggering boundaries and the dilemma of traditional finance indicators.
							</p>
						</td>
					</tr>
				</tbody>
			</table>
			
			<h2>Projects</h2>
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
				<tbody>
					<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
						<td style="padding:20px;width:20%;vertical-align:middle">
							<div class="one">
								<img src='./assets/img/f1tenth_demo.gif' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
							</div>
						</td>
						<td style="padding:20px;width:80%;vertical-align:middle">
							<span class="papertitle">The 17th F1TENTH Grand Prix (HongKong)</span></br>
							Jinghuai Deng, Bingyuan Huang, Xiaoyun Dong, Hua Hu, <strong>Jiahao LI</strong>, and Jianping Wang<br>
							<em>CPS-IoT Week 2024</em><br>
							<a href="https://xyunaaa.github.io/research/f1tenth/">Project Page</a>
							<p></p>
							<p>
								Supervised by <a href="https://scholar.google.com/citations?user=bow_liAAAAAJ&hl=en">Prof. Jianping Wang</a>, our team (FSM Speed) won the championship at the 17th F1TENTH Autonomous Grand Prix during the CPS-IoT Week 2024 in Hong Kong.
							</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body>
</html>
